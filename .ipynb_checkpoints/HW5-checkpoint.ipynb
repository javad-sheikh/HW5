{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error perspectiveTransform\n",
      "error perspectiveTransform\n",
      "error perspectiveTransform\n",
      "error perspectiveTransform\n",
      "error perspectiveTransform\n",
      "error perspectiveTransform\n",
      "error perspectiveTransform\n",
      "error perspectiveTransform\n",
      "error perspectiveTransform\n",
      "error perspectiveTransform\n",
      "error perspectiveTransform\n",
      "error perspectiveTransform\n",
      "error perspectiveTransform\n",
      "error perspectiveTransform\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('vid1.mp4')\n",
    "template = cv2.imread(\"template2.jpg\")\n",
    "GOOD_MATCH_PERCENT = 0.90\n",
    "counter = 0\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "    counter+=1\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if(counter%10==0):\n",
    "        if(ret==False):\n",
    "            break\n",
    "\n",
    "#         gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#         retval,thresholded = cv2.threshold(gray,thresh=70,maxval=250,type=cv2.THRESH_BINARY)\n",
    "        sift = cv2.xfeatures2d.SIFT_create(nfeatures=5, nOctaveLayers=3,\n",
    "                                            contrastThreshold = 0.10, edgeThreshold=10,\n",
    "                                            sigma=2)\n",
    "        keypoints1, descriptors1 = sift.detectAndCompute(frame,None)\n",
    "        keypoints2, descriptors2 = sift.detectAndCompute(template,None)\n",
    "        \n",
    "         # Match features.\n",
    "        matcher = cv2.BFMatcher_create(normType = cv2.NORM_L1,crossCheck = False)\n",
    "        matches = matcher.match(descriptors1, descriptors2, None)\n",
    "        \n",
    "        # Sort matches by score\n",
    "        matches.sort(key=lambda x: x.distance, reverse=False)\n",
    "\n",
    "        # Remove not so good matches\n",
    "        numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "        matches = matches[:numGoodMatches]\n",
    "\n",
    "        # Extract location of good matches\n",
    "        points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "        points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "        for i, match in enumerate(matches):\n",
    "            points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "            points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "#         Find homography\n",
    "        H,mask = cv2.findHomography(points1, points2, cv2.RANSAC,5)\n",
    "        \n",
    "        matchesMask = mask.ravel().tolist()\n",
    "\n",
    "        h,w,_ = template.shape\n",
    "        pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "#         \n",
    "        pts =[pts[0][0],pts[1][0],pts[2][0],pts[3][0]]\n",
    "        pts = np.asarray(pts)\n",
    "        pts = np.array([pts])\n",
    "        \n",
    "        try:\n",
    "            dst = cv2.perspectiveTransform(pts,H)\n",
    "            frame = cv2.polylines(frame,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "        except:\n",
    "            print(\"error perspectiveTransform\")\n",
    "        \n",
    "        # Draw top matches\n",
    "        img_matches = cv2.drawMatches(frame, keypoints1, template, keypoints2, matches, None)\n",
    "\n",
    "        cv2.imshow('video', img_matches)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[80.88643  53.791874]]\n",
      "\n",
      " [[79.44478  63.13087 ]]\n",
      "\n",
      " [[74.116356 97.27798 ]]\n",
      "\n",
      " [[76.701416 80.77654 ]]]\n",
      "error\n",
      "[[[78.178505 70.16278 ]]\n",
      "\n",
      " [[78.444374 68.974525]]\n",
      "\n",
      " [[77.997375 70.9078  ]]\n",
      "\n",
      " [[77.93526  71.19985 ]]]\n",
      "error\n",
      "error\n",
      "[[[75.72245  59.424606]]\n",
      "\n",
      " [[75.872475 59.190674]]\n",
      "\n",
      " [[75.94087  59.195072]]\n",
      "\n",
      " [[75.74794  59.4871  ]]]\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "[[[77.8094   71.49956 ]]\n",
      "\n",
      " [[77.809296 71.4943  ]]\n",
      "\n",
      " [[77.79451  71.560974]]\n",
      "\n",
      " [[77.79582  71.562675]]]\n",
      "error\n",
      "error\n",
      "error\n",
      "[[[78.58529  71.85106 ]]\n",
      "\n",
      " [[78.46927  71.93656 ]]\n",
      "\n",
      " [[78.634796 72.03139 ]]\n",
      "\n",
      " [[78.87112  71.91026 ]]]\n",
      "error\n",
      "[[[77.92311  70.762054]]\n",
      "\n",
      " [[77.92263  70.771614]]\n",
      "\n",
      " [[77.92787  70.77635 ]]\n",
      "\n",
      " [[77.92914  70.76261 ]]]\n",
      "error\n",
      "error\n",
      "error\n",
      "[[[38.050945 86.95396 ]]\n",
      "\n",
      " [[38.052483 86.95441 ]]\n",
      "\n",
      " [[38.049587 86.95357 ]]\n",
      "\n",
      " [[38.04809  86.95313 ]]]\n",
      "error\n",
      "[[[12461.898    34239.133   ]]\n",
      "\n",
      " [[   74.832016    76.37934 ]]\n",
      "\n",
      " [[   66.01609     54.966347]]\n",
      "\n",
      " [[   66.25783     55.111286]]]\n",
      "error\n",
      "[[[78.01091 70.76776]]\n",
      "\n",
      " [[78.50931 70.18064]]\n",
      "\n",
      " [[77.69498 71.88356]]\n",
      "\n",
      " [[77.19312 72.42819]]]\n",
      "error\n",
      "[[[89.12285  70.655556]]\n",
      "\n",
      " [[87.40843  70.55111 ]]\n",
      "\n",
      " [[90.85118  70.903244]]\n",
      "\n",
      " [[93.61943  71.07802 ]]]\n",
      "error\n",
      "[[[55.804585 46.600307]]\n",
      "\n",
      " [[55.674675 46.82508 ]]\n",
      "\n",
      " [[56.398438 45.96185 ]]\n",
      "\n",
      " [[56.772583 45.365406]]]\n",
      "error\n",
      "error\n",
      "error\n",
      "[[[  82.647      94.296425]]\n",
      "\n",
      " [[  75.86267    79.623955]]\n",
      "\n",
      " [[  84.33351   102.069   ]]\n",
      "\n",
      " [[2535.449    5915.308   ]]]\n",
      "error\n",
      "[[[89.400246 64.2606  ]]\n",
      "\n",
      " [[89.38528  64.13762 ]]\n",
      "\n",
      " [[90.25489  64.91127 ]]\n",
      "\n",
      " [[90.306145 65.11797 ]]]\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "[[[71.60835  78.35298 ]]\n",
      "\n",
      " [[72.368126 75.305   ]]\n",
      "\n",
      " [[70.85875  80.58752 ]]\n",
      "\n",
      " [[70.17785  83.380806]]]\n",
      "error\n",
      "[[[69.31362  69.03583 ]]\n",
      "\n",
      " [[68.70207  68.658   ]]\n",
      "\n",
      " [[68.533745 68.49862 ]]\n",
      "\n",
      " [[69.39269  69.02854 ]]]\n",
      "error\n",
      "[[[71.72949  76.18619 ]]\n",
      "\n",
      " [[71.9601   75.643074]]\n",
      "\n",
      " [[72.11046  78.06439 ]]\n",
      "\n",
      " [[71.85318  78.37049 ]]]\n",
      "error\n",
      "[[[85.0152   41.302372]]\n",
      "\n",
      " [[83.85425  41.44483 ]]\n",
      "\n",
      " [[88.00804  41.847553]]\n",
      "\n",
      " [[90.17902  41.640835]]]\n",
      "error\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('vid1.mp4')\n",
    "mask = cv2.imread(\"template.jpg\")\n",
    "GOOD_MATCH_PERCENT = 0.01\n",
    "counter = 0\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "    counter+=1\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if(counter%10==0):\n",
    "        if(ret==False):\n",
    "            break\n",
    "        surf = cv2.xfeatures2d.SURF_create(hessianThreshold = 2200,nOctaves =8,nOctaveLayers = 2)\n",
    "        keypoints1, descriptors1 = surf.detectAndCompute(frame,None)\n",
    "        keypoints2, descriptors2 = surf.detectAndCompute(mask,None)\n",
    "        \n",
    "         # Match features.\n",
    "        matcher = cv2.BFMatcher_create(normType = cv2.NORM_L1,crossCheck = False)\n",
    "        matches = matcher.match(descriptors1, descriptors2, None)\n",
    "        \n",
    "        # Sort matches by score\n",
    "        matches.sort(key=lambda x: x.distance, reverse=False)\n",
    "\n",
    "        # Remove not so good matches\n",
    "        numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "        matches = matches[:numGoodMatches]\n",
    "\n",
    "        # Draw top matches\n",
    "        img_matches = cv2.drawMatches(frame, keypoints1, mask, keypoints2, matches, None)\n",
    "#         cv2.imwrite(\"matches\"+str(counter)+\".jpg\", imMatches)\n",
    "\n",
    "        # Extract location of good matches\n",
    "        points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "        points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "        for i, match in enumerate(matches):\n",
    "            points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "            points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "        # Find homography\n",
    "        retval,homography = cv2.findHomography(points1, points2, cv2.LMEDS)\n",
    "        #-- Get the corners from the image_1 ( the object to be \"detected\" )\n",
    "        obj_corners = np.empty((4,1,2), dtype=np.float32)\n",
    "        obj_corners[0,0,0] = 0\n",
    "        obj_corners[0,0,1] = 0\n",
    "        obj_corners[1,0,0] = mask.shape[1]\n",
    "        obj_corners[1,0,1] = 0\n",
    "        obj_corners[2,0,0] = mask.shape[1]\n",
    "        obj_corners[2,0,1] = mask.shape[0]\n",
    "        obj_corners[3,0,0] = 0\n",
    "        obj_corners[3,0,1] = mask.shape[0]\n",
    "        try:\n",
    "            scene_corners = cv2.perspectiveTransform(obj_corners,retval)\n",
    "            print(scene_corners)\n",
    "            #-- Draw lines between the corners (the mapped object in the scene - image_2 )\n",
    "            cv.line(img_matches, (int(scene_corners[0,0,0] + mask.shape[1]), int(scene_corners[0,0,1])),\\\n",
    "                (int(scene_corners[1,0,0] + mask.shape[1]), int(scene_corners[1,0,1])), (0,255,0), 4)\n",
    "            cv.line(img_matches, (int(scene_corners[1,0,0] + mask.shape[1]), int(scene_corners[1,0,1])),\\\n",
    "                (int(scene_corners[2,0,0] + mask.shape[1]), int(scene_corners[2,0,1])), (0,255,0), 4)\n",
    "            cv.line(img_matches, (int(scene_corners[2,0,0] + mask.shape[1]), int(scene_corners[2,0,1])),\\\n",
    "                (int(scene_corners[3,0,0] + mask.shape[1]), int(scene_corners[3,0,1])), (0,255,0), 4)\n",
    "            cv.line(img_matches, (int(scene_corners[3,0,0] + mask.shape[1]), int(scene_corners[3,0,1])),\\\n",
    "                (int(scene_corners[0,0,0] + mask.shape[1]), int(scene_corners[0,0,1])), (0,255,0), 4)\n",
    "            print('success')\n",
    "        except:\n",
    "            print(\"error\")    \n",
    "        cv2.imshow('video', img_matches)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "[[[ 55.005596 100.951706]]\n",
      "\n",
      " [[ -4.953044 238.64587 ]]\n",
      "\n",
      " [[ 56.393024 -37.22993 ]]\n",
      "\n",
      " [[ 58.0984    13.780359]]]\n",
      "success\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "[[[0. 0.]]\n",
      "\n",
      " [[0. 0.]]\n",
      "\n",
      " [[0. 0.]]\n",
      "\n",
      " [[0. 0.]]]\n",
      "success\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "[[[43.856995 38.039867]]\n",
      "\n",
      " [[51.0752   28.548536]]\n",
      "\n",
      " [[32.312893 53.21939 ]]\n",
      "\n",
      " [[49.892403 30.103811]]]\n",
      "success\n",
      "[[[43.809364 38.102497]]\n",
      "\n",
      " [[43.809364 38.102497]]\n",
      "\n",
      " [[43.809364 38.102497]]\n",
      "\n",
      " [[43.809364 38.102497]]]\n",
      "success\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('vid1.mp4')\n",
    "mask = cv2.imread(\"template.jpg\")\n",
    "GOOD_MATCH_PERCENT = 0.8\n",
    "counter = 0\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "    counter+=1\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if(counter%10==0):\n",
    "        if(ret==False):\n",
    "            break\n",
    "        freak = cv2.xfeatures2d.FREAK_create()\n",
    "        sift = cv2.xfeatures2d.SIFT_create(nfeatures=7, nOctaveLayers=3,\n",
    "                                    contrastThreshold = 0.10, edgeThreshold=10,\n",
    "                                    sigma=2)\n",
    "        keypoints1, descriptors1 = sift.detectAndCompute(frame,None)\n",
    "        keypoints2, descriptors2 = sift.detectAndCompute(mask,None)\n",
    "        keypoints1, descriptors1 = freak.compute(frame,keypoints1)\n",
    "        keypoints2, descriptors2 = freak.compute(mask,keypoints2)\n",
    "        \n",
    "         # Match features.\n",
    "        matcher = cv2.BFMatcher(cv2.NORM_HAMMING2, crossCheck=False)\n",
    "        matches = matcher.match(descriptors1, descriptors2, None)\n",
    "        # Sort matches by score\n",
    "        matches.sort(key=lambda x: x.distance, reverse=False)\n",
    "\n",
    "        # Remove not so good matches\n",
    "        numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "        matches = matches[:numGoodMatches]\n",
    "\n",
    "        # Draw top matches\n",
    "        img_matches = cv2.drawMatches(frame, keypoints1, mask, keypoints2, matches, None)\n",
    "#         cv2.imwrite(\"matches\"+str(counter)+\".jpg\", imMatches)\n",
    "\n",
    "        # Extract location of good matches\n",
    "        points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "        points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "        for i, match in enumerate(matches):\n",
    "            points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "            points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "        # Find homography\n",
    "        retval,homography = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "        #-- Get the corners from the image_1 ( the object to be \"detected\" )\n",
    "        obj_corners = np.empty((4,1,2), dtype=np.float32)\n",
    "        obj_corners[0,0,0] = 0\n",
    "        obj_corners[0,0,1] = 0\n",
    "        obj_corners[1,0,0] = frame.shape[1]\n",
    "        obj_corners[1,0,1] = 0\n",
    "        obj_corners[2,0,0] = frame.shape[1]\n",
    "        obj_corners[2,0,1] = frame.shape[0]\n",
    "        obj_corners[3,0,0] = 0\n",
    "        obj_corners[3,0,1] = frame.shape[0]\n",
    "        try:\n",
    "            scene_corners = cv2.perspectiveTransform(obj_corners,retval)\n",
    "            print(scene_corners)\n",
    "            #-- Draw lines between the corners (the mapped object in the scene - image_2 )\n",
    "            cv.line(img_matches, (int(scene_corners[0,0,0] + mask.shape[1]), int(scene_corners[0,0,1])),\\\n",
    "                (int(scene_corners[1,0,0] + mask.shape[1]), int(scene_corners[1,0,1])), (0,255,0), 4)\n",
    "            cv.line(img_matches, (int(scene_corners[1,0,0] + mask.shape[1]), int(scene_corners[1,0,1])),\\\n",
    "                (int(scene_corners[2,0,0] + mask.shape[1]), int(scene_corners[2,0,1])), (0,255,0), 4)\n",
    "            cv.line(img_matches, (int(scene_corners[2,0,0] + mask.shape[1]), int(scene_corners[2,0,1])),\\\n",
    "                (int(scene_corners[3,0,0] + mask.shape[1]), int(scene_corners[3,0,1])), (0,255,0), 4)\n",
    "            cv.line(img_matches, (int(scene_corners[3,0,0] + mask.shape[1]), int(scene_corners[3,0,1])),\\\n",
    "                (int(scene_corners[0,0,0] + mask.shape[1]), int(scene_corners[0,0,1])), (0,255,0), 4)\n",
    "            print('success')\n",
    "        except:\n",
    "            print(\"error\")    \n",
    "        cv2.imshow('video', img_matches)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('vid1.mp4')\n",
    "mask = cv2.imread(\"template.jpg\")\n",
    "GOOD_MATCH_PERCENT = 0.8\n",
    "counter = 0\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "    counter+=1\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if(counter%10==0):\n",
    "        if(ret==False):\n",
    "            break\n",
    "        sift = cv2.xfeatures2d.SIFT_create(nfeatures=7, nOctaveLayers=3,\n",
    "                                    contrastThreshold = 0.10, edgeThreshold=10,\n",
    "                                    sigma=2)\n",
    "        keypoints1, descriptors1 = sift.detectAndCompute(frame,None)\n",
    "        keypoints2, descriptors2 = sift.detectAndCompute(mask,None)\n",
    "        brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "        keypoints1, descriptors1 = brief.compute(frame,keypoints1)\n",
    "        keypoints2, descriptors2 = brief.compute(mask,keypoints1)\n",
    "        \n",
    "         # Match features.\n",
    "        matcher = cv2.BFMatcher(cv2.NORM_L1, crossCheck=False)\n",
    "        matches = matcher.match(descriptors1, descriptors2, None)\n",
    "        # Sort matches by score\n",
    "        matches.sort(key=lambda x: x.distance, reverse=False)\n",
    "\n",
    "        # Remove not so good matches\n",
    "        numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "        matches = matches[:numGoodMatches]\n",
    "\n",
    "        # Draw top matches\n",
    "        img_matches = cv2.drawMatches(frame, keypoints1, mask, keypoints2, matches, None)\n",
    "#         cv2.imwrite(\"matches\"+str(counter)+\".jpg\", imMatches)\n",
    "\n",
    "        # Extract location of good matches\n",
    "        points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "        points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "        for i, match in enumerate(matches):\n",
    "            points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "            points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "        # Find homography\n",
    "        retval,homography = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "        #-- Get the corners from the image_1 ( the object to be \"detected\" )\n",
    "        obj_corners = np.empty((4,1,2), dtype=np.float32)\n",
    "        obj_corners[0,0,0] = 0\n",
    "        obj_corners[0,0,1] = 0\n",
    "        obj_corners[1,0,0] = frame.shape[1]\n",
    "        obj_corners[1,0,1] = 0\n",
    "        obj_corners[2,0,0] = frame.shape[1]\n",
    "        obj_corners[2,0,1] = frame.shape[0]\n",
    "        obj_corners[3,0,0] = 0\n",
    "        obj_corners[3,0,1] = frame.shape[0]\n",
    "        try:\n",
    "            scene_corners = cv2.perspectiveTransform(obj_corners,retval)\n",
    "            print(scene_corners)\n",
    "            #-- Draw lines between the corners (the mapped object in the scene - image_2 )\n",
    "            cv2.line(img_matches, (int(scene_corners[0,0,0] + mask.shape[1]), int(scene_corners[0,0,1])),\\\n",
    "                (int(scene_corners[1,0,0] + mask.shape[1]), int(scene_corners[1,0,1])), (0,255,0), 4)\n",
    "            cv2.line(img_matches, (int(scene_corners[1,0,0] + mask.shape[1]), int(scene_corners[1,0,1])),\\\n",
    "                (int(scene_corners[2,0,0] + mask.shape[1]), int(scene_corners[2,0,1])), (0,255,0), 4)\n",
    "            cv2.line(img_matches, (int(scene_corners[2,0,0] + mask.shape[1]), int(scene_corners[2,0,1])),\\\n",
    "                (int(scene_corners[3,0,0] + mask.shape[1]), int(scene_corners[3,0,1])), (0,255,0), 4)\n",
    "            cv2.line(img_matches, (int(scene_corners[3,0,0] + mask.shape[1]), int(scene_corners[3,0,1])),\\\n",
    "                (int(scene_corners[0,0,0] + mask.shape[1]), int(scene_corners[0,0,1])), (0,255,0), 4)\n",
    "            print('success')\n",
    "        except:\n",
    "            print(\"error\")    \n",
    "        cv2.imshow('video', img_matches)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inv_CV",
   "language": "python",
   "name": "inv_cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
